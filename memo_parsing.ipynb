{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOH+SWr14r+fgTAMKQNrOhs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tymoshenkoanna/memo_parsing/blob/main/memo_parsing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from urllib.request import urlopen\n",
        "import re\n",
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup as bs4\n",
        "\n",
        "# 1. create a list of links from one url\n",
        "core_url = 'https://ru.openlist.wiki/'\n",
        "search_url = 'https://ru.openlist.wiki/%D0%A1%D0%BB%D1%83%D0%B6%D0%B5%D0%B1%D0%BD%D0%B0%D1%8F:OlSearch?olsearch-name=*&olsearch-birth_min=&olsearch-birth_max=&olsearch-death_min=&olsearch-death_max=&olsearch-birthplace=&olsearch-liveplace=&olsearch-nationality=&olsearch-social=&olsearch-profession=&olsearch-deathplace=&olsearch-burialplace=&olsearch-body=&olsearch-categories=&olsearch-arrest_min=&olsearch-arrest_max=&olsearch-indictment=&olsearch-conviction_min=&olsearch-conviction_max=&olsearch-conviction-org=&olsearch-sentence=&olsearch-detentionplace=&olsearch-release_min=&olsearch-release_max=&olsearch-execution_min=&olsearch-execution_max=&olsearch-archive-case-number=&olsearch-run=1&olsearch-advform=1#OlSearch-results-caption'\n",
        "reqs = requests.get(search_url)\n",
        "bsl = bs4(reqs.text, 'html.parser')\n",
        "\n",
        "#extract all links from the search_url, searching by <a> tag\n",
        "links_http = open('links_http.txt', 'w')\n",
        "for link in bsl.find_all('a'):\n",
        "    links_http.write(\"%s\\n\" % link)\n",
        "\n",
        "#remove <a href=... at the beginning of each link line\n",
        "with open('links_http.txt') as oldfile, open('links_http_cut.txt', 'w') as newfile:\n",
        "    for line in oldfile:\n",
        "         if ':' not in line:\n",
        "            sep_1 = '\"/'\n",
        "            cut_1 = line.split(sep_1, 1)[1]\n",
        "            newfile.write(cut_1)\n",
        "\n",
        "#remove end of each line after > sign, to leave only actual link         \n",
        "links_list=[]\n",
        "with open('links_http_cut.txt') as oldfile_2, open('links_final.txt', 'w') as newfile_2:\n",
        "  for line in oldfile_2:\n",
        "      if '>' in line and ')' in line:\n",
        "            sep_2 = '\">'\n",
        "            cut_2 = line.split(sep_2, 1)[0]\n",
        "            newfile_2.write(\"https://ru.openlist.wiki/%s\\n\" % cut_2)\n",
        "            links_list.append(\"https://ru.openlist.wiki/%s\" % cut_2)\n",
        "            links_list = ['{0} '.format(elem) for elem in links_list] #using list comprehension https://docs.python.org/3/reference/expressions.html#list-displays\n",
        "f = open('links_final.txt', 'r')\n",
        "links_file = f.read()\n",
        "#print(links_file)\n",
        "#print(links_list)\n",
        "\n",
        "#2. creating headers for the table\n",
        "source = requests.get('https://ru.openlist.wiki/H%D0%B8%D0%BA%D0%B8%D1%82%D1%8E%D0%BA_%D0%92%D0%B0%D0%BB%D0%B5%D1%80%D0%B8%D0%B9_%D0%90%D0%BB%D0%B5%D0%BA%D1%81%D0%B0%D0%BD%D0%B4%D1%80%D0%BE%D0%B2%D0%B8%D1%87_(1912)')  \n",
        "memo_data = bs4(source.text, 'lxml') #creates an object with all html data from the page\n",
        "\n",
        "column_names = []\n",
        "for tag_li in memo_data.find_all(\"li\"):#extract all lines that start with <li> tag\n",
        "  for tag_b in tag_li.find_all(\"b\"):\n",
        "    pr_data = (\"{0}: {1}\".format(tag_li.name, tag_li.text))#extract all lines that include <b> tag\n",
        "    for line in pr_data:\n",
        "      sep_3 = ':  '#define separator by which line will be split --> \":  \" colon and two spaces\n",
        "      pr_data_notag = pr_data.split(sep_3, 1)[1]#defined new cleaned data\n",
        "      f_data_1 = pr_data_notag.replace(\": \",\":\") #remove not needed spaces afetr \":\"\n",
        "      final_data = f_data_1.replace(\", \",\",\") #remove not needed spaces after \",\"\n",
        "      sep_table_header = ':'\n",
        "      table_header = final_data.split(sep_table_header, 1)[0]\n",
        "    column_names.append(table_header)\n",
        "\n",
        "print(column_names) #printing column names\n",
        "\n",
        "#3. extracting values and adding them to the table with column names, which were extracted in step 2 above\n",
        "person_data = []\n",
        "\n",
        "source_person = requests.get('https://ru.openlist.wiki/H%D0%B8%D0%BA%D0%B8%D1%82%D1%8E%D0%BA_%D0%92%D0%B0%D0%BB%D0%B5%D1%80%D0%B8%D0%B9_%D0%90%D0%BB%D0%B5%D0%BA%D1%81%D0%B0%D0%BD%D0%B4%D1%80%D0%BE%D0%B2%D0%B8%D1%87_(1912)')  \n",
        "memo_data_person = bs4(source_person.text, 'lxml')\n",
        "\n",
        "for tag_li in memo_data_person.find_all(\"li\"):#extract all lines that start with <li> tag\n",
        "  for tag_b in tag_li.find_all(\"b\"):\n",
        "    pr_data = (\"{0}: {1}\".format(tag_li.name, tag_li.text))#extract all lines that include <b> tag\n",
        "    for line in pr_data:\n",
        "      sep_3 = ':  '#define separator by which line will be split --> \":  \" colon and two spaces\n",
        "      pr_data_notag = pr_data.split(sep_3, 1)[1]#defined new cleaned data\n",
        "      f_data_1 = pr_data_notag.replace(\": \",\":\") #remove not needed spaces afetr \":\"\n",
        "      final_data = f_data_1.replace(\", \",\",\") #remove not needed spaces after \",\"\n",
        "      sep_table_data = ':'\n",
        "      p_data = final_data.split(sep_table_data, 1)[1]\n",
        "    person_data.append(p_data)\n",
        "  \n",
        "#print(person_data) printing all data\n",
        "\n",
        "#4. Create a table\n",
        "import numpy as np\n",
        "from tabulate import tabulate\n",
        "data= [person_data]\n",
        "print(tabulate(data, headers=column_names))\n",
        "\n",
        "#from bs4 import BeautifulSoup\n",
        "#import requests\n",
        "\n",
        "#URL = \"https://www.comnetwork.org/newsletter-archive/\"\n",
        "#page = requests.get(URL)\n",
        "#soup = BeautifulSoup(page.content, \"html.parser\")\n",
        "#for a_href in soup.find_all(\"a\", href=True):\n",
        "#    print(a_href[\"href\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6E_G8OIDfI8K",
        "outputId": "62924961-c45e-4374-b12d-76c884dd5a02"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Дата рождения', 'Место рождения', 'Пол', 'Национальность', 'Гражданство (подданство)', 'Профессия / место работы', 'Место проживания', 'Где и кем арестован', 'Дата ареста', 'Обвинение', 'Осуждение', 'Осудивший орган', 'Статья', 'Приговор', 'Дата реабилитации', 'Реабилитирующий орган', 'Комментарий к аресту', 'Источники данных']\n",
            "Дата рождения    Место рождения                Пол      Национальность    Гражданство (подданство)    Профессия / место работы    Место проживания                      Где и кем арестован     Дата ареста         Обвинение              Осуждение          Осудивший орган                Статья          Приговор    Дата реабилитации    Реабилитирующий орган          Комментарий к аресту                                  Источники данных\n",
            "---------------  ----------------------------  -------  ----------------  --------------------------  --------------------------  ------------------------------------  ----------------------  ------------------  ---------------------  -----------------  -----------------------------  --------------  ----------  -------------------  -----------------------------  ----------------------------------------------------  ----------------------------------------------------------------------------------------------\n",
            "1912 г.          ГССР,Аджарская АССР,г.Батуми  мужчина  русский           СССР                        заключенный Карлаг (?)      Каз.ССР,Акмолинская обл.,г.Кокчетав.  Оперотдел Карлаг HКВД.  15 октября 1942 г.  АСА в военное время (  18 апреля 1943 г.  Акмолинский облсуд,18.04.1943  58-10 УК РСФСР  8 лет ИТЛ.  20 сентября 1972 г.  Судебная коллегия ВС Каз.ССР.  Реабилитирована за отсутствием состава преступления.  Список репрессированных лиц,архивные уголовные дела на которых хранятся в КНБ РК (pomnirod.ru)\n"
          ]
        }
      ]
    }
  ]
}