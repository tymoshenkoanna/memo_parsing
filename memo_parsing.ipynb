{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO6X3AZ+DMO90hBVnz4TthC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tymoshenkoanna/memo_parsing/blob/main/memo_parsing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from urllib.request import urlopen\n",
        "import re\n",
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup as bs4\n",
        "\n",
        "# 1. create a list of links from one url\n",
        "core_url = 'https://ru.openlist.wiki/'\n",
        "search_url = 'https://ru.openlist.wiki/%D0%A1%D0%BB%D1%83%D0%B6%D0%B5%D0%B1%D0%BD%D0%B0%D1%8F:OlSearch?olsearch-name=*&olsearch-birth_min=&olsearch-birth_max=&olsearch-death_min=&olsearch-death_max=&olsearch-birthplace=&olsearch-liveplace=&olsearch-nationality=&olsearch-social=&olsearch-profession=&olsearch-deathplace=&olsearch-burialplace=&olsearch-body=&olsearch-categories=&olsearch-arrest_min=&olsearch-arrest_max=&olsearch-indictment=&olsearch-conviction_min=&olsearch-conviction_max=&olsearch-conviction-org=&olsearch-sentence=&olsearch-detentionplace=&olsearch-release_min=&olsearch-release_max=&olsearch-execution_min=&olsearch-execution_max=&olsearch-archive-case-number=&olsearch-run=1&olsearch-advform=1#OlSearch-results-caption'\n",
        "reqs = requests.get(search_url)\n",
        "bsl = bs4(reqs.text, 'html.parser')\n",
        "\n",
        "#extract all links from the search_url, searching by <a> tag\n",
        "links_http = open('links_http.txt', 'w')\n",
        "for link in bsl.find_all('a'):\n",
        "    links_http.write(\"%s\\n\" % link)\n",
        "\n",
        "#remove <a href=... at the beginning of each link line\n",
        "with open('links_http.txt') as oldfile, open('links_http_cut.txt', 'w') as newfile:\n",
        "    for line in oldfile:\n",
        "         if ':' not in line:\n",
        "            sep_1 = '\"/'\n",
        "            cut_1 = line.split(sep_1, 1)[1]\n",
        "            newfile.write(cut_1)\n",
        "\n",
        "#remove end of each line after > sign, to leave only actual link         \n",
        "\n",
        "#DON'T DELETE, WORKING CODE. Below will extract all links from the saved file. Due to the amount of links on the list it's commented out, and just three links are saved as a list as PCO of the code\n",
        "#links_list=[]\n",
        "#with open('links_http_cut.txt') as oldfile_2, open('links_final.txt', 'w') as newfile_2:\n",
        "#  for line in oldfile_2:\n",
        "#      if '>' in line and ')' in line:\n",
        "#            sep_2 = '\">'\n",
        "#            cut_2 = line.split(sep_2, 1)[0]\n",
        "#            newfile_2.write(\"https://ru.openlist.wiki/%s\\n\" % cut_2)\n",
        "#            links_list.append(\"https://ru.openlist.wiki/%s\" % cut_2)\n",
        "#            links_list = ['{0} '.format(elem) for elem in links_list] #using list comprehension https://docs.python.org/3/reference/expressions.html#list-displays\n",
        "#f = open('links_final.txt', 'r')\n",
        "#links_file = f.read()\n",
        "#print(links_file)\n",
        "#links \n",
        "links_list=['https://ru.openlist.wiki/H%D0%B8%D0%BA%D0%B8%D1%82%D1%8E%D0%BA_%D0%92%D0%B0%D0%BB%D0%B5%D1%80%D0%B8%D0%B9_%D0%90%D0%BB%D0%B5%D0%BA%D1%81%D0%B0%D0%BD%D0%B4%D1%80%D0%BE%D0%B2%D0%B8%D1%87_(1912)                                                                                               ', 'https://ru.openlist.wiki/%D0%81_%D0%90%D0%BB%D0%B5%D0%BA%D1%81%D0%B0%D0%BD%D0%B4%D1%80_%D0%90%D0%BB%D0%B5%D0%BA%D1%81%D0%B0%D0%BD%D0%B4%D1%80%D0%BE%D0%B2%D0%B8%D1%87_(1911)                                                                                              ','https://ru.openlist.wiki/%D0%81_%D0%90%D0%BB%D0%B5%D0%BA%D1%81%D0%B0%D0%BD%D0%B4%D1%80_%D0%90%D0%BB%D0%B5%D0%BA%D1%81%D0%B0%D0%BD%D0%B4%D1%80%D0%BE%D0%B2%D0%B8%D1%87_(1911)']\n",
        "print(links_list)\n",
        "\n",
        "#2. creating headers for the table\n",
        "source = requests.get('https://ru.openlist.wiki/H%D0%B8%D0%BA%D0%B8%D1%82%D1%8E%D0%BA_%D0%92%D0%B0%D0%BB%D0%B5%D1%80%D0%B8%D0%B9_%D0%90%D0%BB%D0%B5%D0%BA%D1%81%D0%B0%D0%BD%D0%B4%D1%80%D0%BE%D0%B2%D0%B8%D1%87_(1912)')  \n",
        "memo_data = bs4(source.text, 'lxml') #creates an object with all html data from the page\n",
        "\n",
        "column_names = []\n",
        "for tag_li in memo_data.find_all(\"li\"):#extract all lines that start with <li> tag\n",
        "  for tag_b in tag_li.find_all(\"b\"): #extract all lines that include <b> tag\n",
        "    pr_data = (\"{0}: {1}\".format(tag_li.name, tag_li.text))\n",
        "    #print(pr_data)\n",
        "    #for line in pr_data:\n",
        "    for line in pr_data.splitlines():\n",
        "      #print(line)\n",
        "      sep_3 = ':  '#define separator by which line will be split --> \":  \" colon and two spaces\n",
        "      #print(line)\n",
        "      pr_data_notag = pr_data.split(sep_3, 1)[1]#defined new cleaned data\n",
        "      f_data_1 = pr_data_notag.replace(\": \",\":\") #remove not needed spaces afetr \":\"\n",
        "      final_data = f_data_1.replace(\", \",\",\") #remove not needed spaces after \",\"\n",
        "      sep_table_header = ':'\n",
        "      table_header = final_data.split(sep_table_header, 1)[0]\n",
        "    column_names.append(table_header)\n",
        "\n",
        "print(column_names) #printing column names\n",
        "\n",
        "#3. extracting values and adding them to the table with column names, which were extracted in step 2 above\n",
        "extract = []\n",
        "person_data = []\n",
        "for link in links_list:\n",
        "    #print(link)\n",
        "    source_person = requests.get(link)\n",
        "    memo_data_person = bs4(source_person.text, 'lxml')\n",
        "    #print(memo_data_person)\n",
        "    for tag_li in memo_data_person.find_all(\"li\"):#extract all lines that start with <li> tag\n",
        "      #print(tag_li)\n",
        "      for tag_b in tag_li.find_all(\"b\"): #extract all lines that include <b> tag  \n",
        "        #print(tag_b)\n",
        "        pr_data = (\"{0}: {1}\".format(tag_li.name, tag_li.text))\n",
        "        #print(pr_data)\n",
        "        pr_data_notag = pr_data.split(\":  \", 1)[1]\n",
        "        f_data_1 = pr_data_notag.replace(\": \",\":\") #remove not needed spaces afetr \":\"\n",
        "        final_data = f_data_1.replace(\", \",\",\") #remove not needed spaces after \",\"\n",
        "        #print(final_data)\n",
        "        person_data.append(final_data)\n",
        "\n",
        "#print(person_data)\n",
        "\n",
        "lists =[[]]\n",
        "for i in person_data:\n",
        "    if i == 'Источники данных:':\n",
        "        lists.append([])\n",
        "    else:\n",
        "        lists[-1].append(i)\n",
        "pprint(lists)\n",
        "                           "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "we7LF9hoI_78",
        "outputId": "d88705e5-3361-4709-b700-332d0c5a8b9e"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['https://ru.openlist.wiki/H%D0%B8%D0%BA%D0%B8%D1%82%D1%8E%D0%BA_%D0%92%D0%B0%D0%BB%D0%B5%D1%80%D0%B8%D0%B9_%D0%90%D0%BB%D0%B5%D0%BA%D1%81%D0%B0%D0%BD%D0%B4%D1%80%D0%BE%D0%B2%D0%B8%D1%87_(1912)                                                                                               ', 'https://ru.openlist.wiki/%D0%81_%D0%90%D0%BB%D0%B5%D0%BA%D1%81%D0%B0%D0%BD%D0%B4%D1%80_%D0%90%D0%BB%D0%B5%D0%BA%D1%81%D0%B0%D0%BD%D0%B4%D1%80%D0%BE%D0%B2%D0%B8%D1%87_(1911)                                                                                              ', 'https://ru.openlist.wiki/%D0%81_%D0%90%D0%BB%D0%B5%D0%BA%D1%81%D0%B0%D0%BD%D0%B4%D1%80_%D0%90%D0%BB%D0%B5%D0%BA%D1%81%D0%B0%D0%BD%D0%B4%D1%80%D0%BE%D0%B2%D0%B8%D1%87_(1911)']\n",
            "['Дата рождения', 'Место рождения', 'Пол', 'Национальность', 'Гражданство (подданство)', 'Профессия / место работы', 'Место проживания', 'Где и кем арестован', 'Дата ареста', 'Обвинение', 'Осуждение', 'Осудивший орган', 'Статья', 'Приговор', 'Дата реабилитации', 'Реабилитирующий орган', 'Комментарий к аресту', 'Источники данных']\n",
            "[['Дата рождения:1912\\xa0г.',\n",
            "  'Место рождения:ГССР,Аджарская АССР,г.Батуми',\n",
            "  'Пол:мужчина',\n",
            "  'Национальность:русский',\n",
            "  'Гражданство (подданство):СССР',\n",
            "  'Профессия / место работы:заключенный Карлаг (?)',\n",
            "  'Место проживания:Каз.ССР,Акмолинская обл.,г.Кокчетав.',\n",
            "  'Где и кем арестован:Оперотдел Карлаг HКВД.',\n",
            "  'Дата ареста:15 октября 1942\\xa0г.',\n",
            "  'Обвинение:АСА в военное время (',\n",
            "  'Осуждение:18 апреля 1943\\xa0г.',\n",
            "  'Осудивший орган:Акмолинский облсуд,18.04.1943',\n",
            "  'Статья:58-10 УК РСФСР',\n",
            "  'Приговор:8 лет ИТЛ.',\n",
            "  'Дата реабилитации:20 сентября 1972\\xa0г.',\n",
            "  'Реабилитирующий орган:Судебная коллегия ВС Каз.ССР.',\n",
            "  'Комментарий к аресту:Реабилитирована за отсутствием состава преступления.',\n",
            "  'Источники данных:Список репрессированных лиц,архивные уголовные дела на '\n",
            "  'которых хранятся в КНБ РК (pomnirod.ru)',\n",
            "  'Дата рождения:1911\\xa0г.',\n",
            "  'Место рождения:Китай,Харбин',\n",
            "  'Пол:мужчина',\n",
            "  'Дата ареста:1934\\xa0г.',\n",
            "  'Архивное дело:П-19905',\n",
            "  'Источники данных:ГА РФ,архивно-следственное дело',\n",
            "  'Дата рождения:1911\\xa0г.',\n",
            "  'Место рождения:Китай,Харбин',\n",
            "  'Пол:мужчина',\n",
            "  'Дата ареста:1934\\xa0г.',\n",
            "  'Архивное дело:П-19905',\n",
            "  'Источники данных:ГА РФ,архивно-следственное дело']]\n"
          ]
        }
      ]
    }
  ]
}